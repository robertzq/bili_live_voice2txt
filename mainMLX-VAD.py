import subprocess
import time
import sys
import numpy as np
import threading
import queue
import mlx_whisper # üëà ÂÖ≥ÈîÆÔºöApple ÂéüÁîüÂ∫ì
import warnings
import torch
warnings.filterwarnings("ignore")

# ================= ÈÖçÁΩÆÂå∫ =================
ROOM_ID = "24692760" #1950858520 jiojio. 24692760 1946526637 1749934708 1879296633. 6838597. 32673043 1884963175 1755260650 24692760
# ËøôÈáå‰ΩøÁî®ÁöÑÊòØ MLX Ê†ºÂºèÁöÑ Large-v3ÔºåÁ≤æÂ∫¶Êª°Ë°ÄÔºåÈÄüÂ∫¶È£ûÂø´
MODEL_PATH = "mlx-community/whisper-large-v3-mlx"
# =========================================

# ÈòüÂàóÔºàÂõ†‰∏∫ MLX Â§ÑÁêÜÊûÅÂø´ÔºåËøôÈáåÂá†‰πéÊ∞∏ËøúÊòØÁ©∫ÁöÑÔºå‰∏ç‰ºöÁßØÂéãÔºâ
audio_queue = queue.Queue()
IGNORE_KEYWORDS = [
    "by bwd6", "Â≠óÂπïby", "Amara.org", "‰ºò‰ºòÁã¨Êí≠ÂâßÂú∫", "compared compared",
    "YoYo Television", "‰∏çÂêùÁÇπËµû", "ËÆ¢ÈòÖÊàëÁöÑÈ¢ëÈÅì", "Copyright"
]
# === üéß ÂàùÂßãÂåñ VAD Ê®°Âûã ===
print("üõ† Ê≠£Âú®Âä†ËΩΩ VAD Ê®°Âûã...")
# Âä†ËΩΩ silero VADÔºåÈùûÂ∏∏ËΩªÈáèÔºåÂá†ÁßíÈíüÂ∞±Â•Ω
vad_model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                                  model='silero_vad',
                                  force_reload=False,
                                  trust_repo=True)
(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils
print("‚úÖ VAD Ê®°ÂûãÂä†ËΩΩÂÆåÊØï")
def stream_producer(room_id):
    """Áîü‰∫ßËÄÖÔºöË¥üË¥£ÊäìÂèñ BÁ´ô Áõ¥Êí≠ÊµÅ"""
    print(f"üîó [Áîü‰∫ßËÄÖ] Ê≠£Âú®ËøûÊé•Áõ¥Êí≠Èó¥: {room_id} ...")
    streamlink_cmd = ["streamlink", "--twitch-disable-ads", f"https://live.bilibili.com/{room_id}", "best", "--stdout"]
    ffmpeg_cmd = ["ffmpeg", "-i", "pipe:0", "-vn", "-ac", "1", "-ar", "16000", "-f", "s16le", "-loglevel", "quiet", "-"]
    
    try:
        process_streamlink = subprocess.Popen(streamlink_cmd, stdout=subprocess.PIPE)
        process_ffmpeg = subprocess.Popen(ffmpeg_cmd, stdin=process_streamlink.stdout, stdout=subprocess.PIPE)
        print("üéß [Áîü‰∫ßËÄÖ] Èü≥È¢ëÊµÅÂ∑≤Âª∫Á´ãÔºåÂºÄÂßãÂ≠òÂÖ•ÈòüÂàó...")
        
        # üí° Âª∫ËÆÆÔºöÊääÂàáÁâáÊîπÂ∞è‰∏ÄÁÇπÔºåÊØîÂ¶Ç 5-6Áßí„ÄÇ
        # 10ÁßíÂ§™ÈïøÔºå‰∏á‰∏ÄÂâç5ÁßíÂî±Ê≠åÔºåÂêé5ÁßíËØ¥ËØùÔºåVADÂèØËÉΩ‰ºöÂõ†‰∏∫Êúâ‰∫∫Â£∞ËÄåÊääÊï¥ÊÆµÊîæËøáÂéª
        chunk_seconds = 8 
        chunk_size = 16000 * 2 * chunk_seconds
        
        while True:
            in_bytes = process_ffmpeg.stdout.read(chunk_size)
            if not in_bytes: break
            audio_data = np.frombuffer(in_bytes, np.int16).flatten().astype(np.float32) / 32768.0
            audio_queue.put(audio_data)
    except Exception as e:
        print(f"Áîü‰∫ßËÄÖÂá∫Èîô: {e}")
    finally:
        if 'process_ffmpeg' in locals(): process_ffmpeg.kill()
        if 'process_streamlink' in locals(): process_streamlink.kill()

def is_hallucination(text):
    for kw in IGNORE_KEYWORDS:
        if kw.lower() in text.lower():
            return True
    return False

def check_voice_activity(audio_np, model):
    # Silero ÈúÄË¶Å Tensor Ê†ºÂºè
    audio_tensor = torch.from_numpy(audio_np)
    # Ëé∑ÂèñËØ≠Èü≥Êó∂Èó¥Êà≥
    speech_timestamps = get_speech_timestamps(audio_tensor, model, sampling_rate=16000)
    
    # Â¶ÇÊûúÊ£ÄÊµãÂà∞ÁöÑËØ≠Èü≥ÁâáÊÆµÊÄªÊó∂ÈïøÂ§™Áü≠ÔºàÊØîÂ¶ÇÂ∞ë‰∫é 0.5ÁßíÔºâÔºåÂ∞±ËÆ§‰∏∫ÊòØÂô™Èü≥ÊàñËØØËß¶
    if not speech_timestamps:
        return False
    
    total_speech_time = sum([(i['end'] - i['start']) for i in speech_timestamps]) / 16000
    # ÈòàÂÄºÔºöËá≥Â∞ëË¶ÅÊúâ 0.5 ÁßíÁöÑ‰∫∫Â£∞ÊâçÁÆóÊï∞
    return total_speech_time > 0.5

def main():
    print(f"üöÄ [Ê∂àË¥πËÄÖ] Ê≠£Âú®Âä†ËΩΩ MLX Large-v3 Ê®°Âûã...")
    t = threading.Thread(target=stream_producer, args=(ROOM_ID,), daemon=True)
    t.start()
    
    log_file = f"{ROOM_ID}_mlx_log_{int(time.time())}.txt"
    last_text = ""
    
    print("ü§ñ [Ê∂àË¥πËÄÖ] ÂºïÊìéÂêØÂä®...")

    while True:
        try:
            audio_data = audio_queue.get()
            
            # === üõë Á¨¨‰∏ÄÈÅìÂÖ≥Âç°ÔºöVAD Ê£ÄÊµã ===
            # Â¶ÇÊûúËøô‰∏ÄÊÆµÈü≥È¢ëÈáåÊ≤°ÊúâÊúâÊïà‰∫∫Â£∞ÔºåÁõ¥Êé•Ë∑≥ËøáÔºÅ
            if not check_voice_activity(audio_data, vad_model):
                print(f"üéµ [VAD] Ê£ÄÊµãÂà∞Á∫ØÈü≥‰πê/ÈùôÈü≥ÔºåË∑≥Ëøá Whisper...")
                continue # Áõ¥Êé•Ëøõ‰∏ã‰∏ÄÊ¨°Âæ™ÁéØÔºå‰∏çË∑ë Whisper
            
           
            # === ‚ö°Ô∏è Á¨¨‰∫åÈÅìÂÖ≥Âç°ÔºöWhisper ===
            start_t = time.time()
            result = mlx_whisper.transcribe(
                audio_data, 
                path_or_hf_repo=MODEL_PATH,
                language="zh",
                verbose=False,
                
                # Á®çÂæÆË∞ÉÈ´ò‰∏ÄÁÇπÊó†Â£∞ÈòàÂÄº
                no_speech_threshold=0.4, 
                logprob_threshold=-0.8
            )
            
            text = result["text"].strip()
            
            if len(text) > 1 and text != last_text and not is_hallucination(text):
                cost_time = time.time() - start_t
                timestamp = time.strftime("%H:%M:%S")
                line = f"[{timestamp}] (‚ö°Ô∏è{cost_time:.2f}s) {text}"
                print(line)
                with open(log_file, "a", encoding="utf-8") as f:
                    f.write(line + "\n")
                last_text = text
                        
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    main()