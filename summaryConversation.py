import requests
import json
import os

# --- å…³é”®ï¼šå¼ºåˆ¶å…³é—­å½“å‰è¿›ç¨‹çš„ä»£ç†è®¾ç½® ---
os.environ['no_proxy'] = 'localhost,127.0.0.1'
if "http_proxy" in os.environ: del os.environ["http_proxy"]
if "https_proxy" in os.environ: del os.environ["https_proxy"]

# é…ç½®ã€‚qwen2.5-coder:32b. qwen3-coder:30b. deepseek-r1:32b
MODEL = "qwen3-coder:30b" # å»ºè®®ç¡®ä¿ä½ å·²ç»ç”¨ ollama pull ä¸‹å¥½äº†
FILE_PATH = "æŸšé”–å­_1894720970_mlx_log_1772164506.txt" # æ›¿æ¢ä¸ºä½ çš„çœŸå®æ–‡ä»¶å
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"

try:
    with open(FILE_PATH, "r", encoding="utf-8") as f:
        content = f.read()
except FileNotFoundError:
    print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {FILE_PATH}")
    exit()

prompt = f"""
ä½ ç°åœ¨æ˜¯ä¸€åèµ„æ·±çš„ B ç«™ç›´æ’­è§‚å¯Ÿå‘˜ã€‚è¯·é’ˆå¯¹ä»¥ä¸‹ã€æŸšé”–å­ã€‘çš„ç›´æ’­å½•éŸ³æ–‡æœ¬ï¼Œè¿›è¡Œä¸€æ¬¡â€œæ‰‹æœ¯çº§â€çš„æ·±åº¦æ€»ç»“ã€‚

### ä»»åŠ¡è¦æ±‚ï¼š
1. **æ—¶é—´çº¿è¿˜åŸ**ï¼šæŒ‰ç…§ç›´æ’­è¿›è¡Œçš„é¡ºåºï¼Œæ¢³ç†å‡ºè‡³å°‘ 5-8 ä¸ªå…³é”®çš„æ—¶é—´èŠ‚ç‚¹å’Œå¯¹åº”å‘ç”Ÿçš„äº‹ä»¶ã€‚
2. **æ ¸å¿ƒæ§½ç‚¹/æ¢—**ï¼šæå–ç›´æ’­é—´å‡ºç°çš„ç‰¹å®šé»‘è¯ã€æ¢—ï¼ˆæ¯”å¦‚æåˆ°çš„â€œå‡‰èœâ€ã€â€œæ²™å°˜æš´â€å…·ä½“æ˜¯æ€ä¹ˆå›äº‹ï¼‰ã€‚
3. **å…³é”®äººç‰©ç”»åƒ**ï¼šé™¤äº†ä¸»æ’­ï¼Œæåˆ°äº†å“ªäº›é‡è¦çš„ç²‰ä¸æˆ–è§‚ä¼—ï¼ˆå¦‚â€œç»å‘½å±±ä¸»â€ã€â€œå¦™ç¬”ç”ŸèŠ±â€ï¼‰ï¼Œä»–ä»¬è¯´äº†ä»€ä¹ˆé‡è¦çš„è¯ï¼Ÿ
4. **æƒ…æ„Ÿæ›²çº¿**ï¼šä¸»æ’­ä»Šå¤©çš„æƒ…ç»ªçŠ¶æ€å¦‚ä½•ï¼Ÿï¼ˆæ¯”å¦‚ï¼šç–²æƒ«ã€å…´å¥‹ã€è¿˜æ˜¯åœ¨ç”»é¥¼ï¼Ÿï¼‰
5. **ç¡¬æ ¸ç»†èŠ‚**ï¼šä¸è¦è¯´â€œæåˆ°äº†ä¸€äº›æ•æ„Ÿé—®é¢˜â€ï¼Œè¦å†™å‡ºâ€œå…³äºæ–‡ä»¶å…±äº«ï¼Œä¸»æ’­å…·ä½“æ˜¯æ€ä¹ˆæ¾„æ¸…çš„ï¼Œè®¾ç½®äº†å“ªäº›æ•æ„Ÿè¯â€ã€‚

### å¾…åˆ†ææ–‡æœ¬ï¼š
{content}

æœ€åï¼Œè¯·ç”Ÿæˆä¸€æ®µ Mermaid æ ¼å¼çš„æ€ç»´å¯¼å›¾ä»£ç ï¼Œæ¦‚æ‹¬æœ¬æ¬¡ç›´æ’­çš„ç»“æ„ã€‚
"""

payload = {
    "model": MODEL,
    "prompt": prompt,
    "stream": True,
    "options": {
        "num_ctx": 65536, # 48GB å†…å­˜å¤Ÿå¤§ï¼Œç›´æ¥å¼€ 64k çª—å£
        "temperature": 0.3
    }
}

print(f"ğŸš€ æ­£åœ¨å‘é€è¯·æ±‚åˆ° Ollama (æ¨¡å‹: {MODEL})...")

try:
    # å¢åŠ  proxies={'http': None, 'https': None} åŒé‡ä¿é™©
    response = requests.post(OLLAMA_URL, json=payload, stream=True, proxies={'http': None, 'https': None})
    
    # å¦‚æœ HTTP çŠ¶æ€ç ä¸æ˜¯ 200ï¼Œç›´æ¥æ‰“å°å‡ºæ¥
    if response.status_code != 200:
        print(f"âŒ Ollama è¿”å›é”™è¯¯ï¼Œä»£ç : {response.status_code}")
        print(response.text)
        exit()

    for line in response.iter_lines():
        if line:
            try:
                chunk = json.loads(line.decode('utf-8'))
                if "response" in chunk:
                    print(chunk["response"], end="", flush=True)
                if chunk.get("done"):
                    print("\n\nâœ… æ€»ç»“å®Œæˆï¼")
            except json.JSONDecodeError:
                print(f"\nâš ï¸ æ”¶åˆ°é JSON æ•°æ®: {line}")
except requests.exceptions.ConnectionError:
    print("âŒ æ— æ³•è¿æ¥åˆ° Ollamaã€‚è¯·ç¡®ä¿ä½ è¿è¡Œäº† 'ollama serve' å¹¶ä¸”ç«¯å£ 11434 å¯ç”¨ã€‚")