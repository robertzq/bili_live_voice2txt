import subprocess
import time
import sys
import json
import os # å¯é€‰ï¼Œç”¨äºæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
import numpy as np
import threading
import queue
import warnings
import torch
from faster_whisper import WhisperModel  # ğŸ‘ˆ æ›¿æ¢äº† mlx_whisper

warnings.filterwarnings("ignore")

# ================= é…ç½®åŒº =================
#ROOM_ID = "24692760" 
# Windows ä¸Šæ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° C:\Users\ä½ çš„ç”¨æˆ·å\.cache\huggingface...
MODEL_SIZE = "large-v3" 
# =========================================

audio_queue = queue.Queue()
IGNORE_KEYWORDS = [
    "by bwd6", "å­—å¹•by", "Amara.org", "ä¼˜ä¼˜ç‹¬æ’­å‰§åœº", "compared compared",
    "YoYo Television", "ä¸åç‚¹èµ", "è®¢é˜…æˆ‘çš„é¢‘é“", "Copyright", "The following content"
]

# === ğŸ§ åˆå§‹åŒ– VAD æ¨¡å‹ (GPU åŠ é€Ÿ) ===
print("ğŸ›  æ­£åœ¨åŠ è½½ VAD æ¨¡å‹...")
# æ£€æŸ¥æ˜¯å¦æœ‰ NVIDIA æ˜¾å¡
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ–¥ï¸ è¿è¡Œè®¾å¤‡: {DEVICE} (RTX 3060 Ti åº”è¯¥æ˜¾ç¤º cuda)")

vad_model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                                  model='silero_vad',
                                  force_reload=False,
                                  trust_repo=True)
(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils
vad_model.to(DEVICE) # æŠŠ VAD æ¨¡å‹ä¹Ÿä¸¢åˆ°æ˜¾å¡ä¸Š
print("âœ… VAD æ¨¡å‹åŠ è½½å®Œæ¯•")


# === ğŸš€ åˆå§‹åŒ– Whisper æ¨¡å‹ (Faster-Whisper) ===
print(f"ğŸš€ æ­£åœ¨åŠ è½½ Faster-Whisper ({MODEL_SIZE})...")
# compute_type="float16" æ˜¯ 3060Ti çš„ç”œç‚¹ç²¾åº¦ï¼Œé€Ÿåº¦å¿«ä¸”ç²¾åº¦ä¸æŸå¤±
whisper_model = WhisperModel(MODEL_SIZE, device="cuda", compute_type="float16")
print("âœ… Whisper æ¨¡å‹åŠ è½½å®Œæ¯•")


def stream_producer(room_id):
    """ç”Ÿäº§è€…ï¼šè´Ÿè´£æŠ“å– Bç«™ ç›´æ’­æµ"""
    print(f"ğŸ”— [ç”Ÿäº§è€…] æ­£åœ¨è¿æ¥ç›´æ’­é—´: {room_id} ...")
    
    # Windows ä¸‹ subprocess è°ƒç”¨å‘½ä»¤ï¼Œæœ‰æ—¶å€™éœ€è¦ shell=True æˆ–è€…å®Œæ•´çš„ exe è·¯å¾„
    # å¦‚æœæŠ¥é”™æ‰¾ä¸åˆ°å‘½ä»¤ï¼Œè¯·ç¡®ä¿ streamlink å’Œ ffmpeg åœ¨ç¯å¢ƒå˜é‡é‡Œ
    streamlink_cmd = ["streamlink", "--twitch-disable-ads", f"https://live.bilibili.com/{room_id}", "best", "--stdout"]
    ffmpeg_cmd = ["ffmpeg", "-i", "pipe:0", "-vn", "-ac", "1", "-ar", "16000", "-f", "s16le", "-loglevel", "quiet", "-"]
    
    try:
        # Windows ä¸Šå¯èƒ½éœ€è¦ shell=True æ¥å¯»æ‰¾å‘½ä»¤ï¼Œä½†é€šå¸¸ä¸å»ºè®®ã€‚å¦‚æœè·‘ä¸é€šï¼Œå°è¯•æ”¹ä¸º True
        process_streamlink = subprocess.Popen(streamlink_cmd, stdout=subprocess.PIPE)
        process_ffmpeg = subprocess.Popen(ffmpeg_cmd, stdin=process_streamlink.stdout, stdout=subprocess.PIPE)
        print("ğŸ§ [ç”Ÿäº§è€…] éŸ³é¢‘æµå·²å»ºç«‹ï¼Œå¼€å§‹å­˜å…¥é˜Ÿåˆ—...")
        
        # åˆ‡ç‰‡æ—¶é—´
        chunk_seconds = 8 
        chunk_size = 16000 * 2 * chunk_seconds
        
        while True:
            in_bytes = process_ffmpeg.stdout.read(chunk_size)
            if not in_bytes: break
            
            # è½¬ä¸º float32
            audio_data = np.frombuffer(in_bytes, np.int16).flatten().astype(np.float32) / 32768.0
            audio_queue.put(audio_data)
            
    except Exception as e:
        print(f"ç”Ÿäº§è€…å‡ºé”™: {e}")
        print("âš ï¸ æç¤ºï¼šå¦‚æœåœ¨ Windows ä¸ŠæŠ¥é”™æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ FFmpeg æ˜¯å¦æ·»åŠ åˆ°äº†ç¯å¢ƒå˜é‡ Path ä¸­")
    finally:
        if 'process_ffmpeg' in locals(): process_ffmpeg.kill()
        if 'process_streamlink' in locals(): process_streamlink.kill()

def is_hallucination(text):
    for kw in IGNORE_KEYWORDS:
        if kw.lower() in text.lower():
            return True
    return False

def check_voice_activity(audio_np, model):
    # numpy -> tensor -> gpu
    audio_tensor = torch.from_numpy(audio_np).to(DEVICE)
    
    # è·å–è¯­éŸ³æ—¶é—´æˆ³
    speech_timestamps = get_speech_timestamps(audio_tensor, model, sampling_rate=16000)
    
    if not speech_timestamps:
        return False
    
    total_speech_time = sum([(i['end'] - i['start']) for i in speech_timestamps]) / 16000
    return total_speech_time > 0.5

def load_config(file_path):
    """è¯»å– JSON é…ç½®æ–‡ä»¶"""
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {file_path}")
        sys.exit(1)
        
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        room_id = str(config.get("room_id", "")).strip()
        name = config.get("streamer_name", "Unknown").strip()
        
        if not room_id:
            print("âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ 'room_id'")
            sys.exit(1)
            
        return room_id, name
    except json.JSONDecodeError:
        print(f"âŒ é”™è¯¯: é…ç½®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡® (ä¸æ˜¯æœ‰æ•ˆçš„ JSON): {file_path}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®å‡ºé”™: {e}")
        sys.exit(1)

def main():
    if len(sys.argv) < 2:
        print("âŒ é”™è¯¯: è¯·æä¾›é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚: python main.py room.json")
        return

    # 2. è¯»å–é…ç½® (è¿™é‡Œè°ƒç”¨ä½ åˆšåŠ çš„ load_config)
    config_file = sys.argv[1]
    room_id, streamer_name = load_config(config_file)
    print(f"âœ… è¯»å–é…ç½®æˆåŠŸ -> ä¸»æ’­: {streamer_name} | æˆ¿é—´å·: {room_id}")

    t = threading.Thread(target=stream_producer, args=(room_id,), daemon=True)
    t.start()
    
    log_file = f"{streamer_name}_{room_id}_win_mlx_log_{int(time.time())}.txt"
    last_text = ""
    
    print("ğŸ¤– [æ¶ˆè´¹è€…] å¼•æ“å¯åŠ¨ (CUDA åŠ é€Ÿä¸­)...")

    while True:
        try:
            audio_data = audio_queue.get()
            
            # === ğŸ›‘ VAD æ£€æµ‹ ===
            if not check_voice_activity(audio_data, vad_model):
                print(f"ğŸµ [VAD] é™éŸ³/çº¯éŸ³ä¹ï¼Œè·³è¿‡...")
                continue 
            
            # === âš¡ï¸ Whisper è½¬å†™ (CUDA) ===
            start_t = time.time()
            
            # faster-whisper çš„è°ƒç”¨æ–¹å¼ç•¥æœ‰ä¸åŒ
            # beam_size=5 æ˜¯æ ‡å‡†ç²¾åº¦ï¼Œå¦‚æœæƒ³è¦æ›´å¿«å¯ä»¥è®¾ä¸º 1
            segments, info = whisper_model.transcribe(
                audio_data, 
                beam_size=5, 
                language="zh",
                vad_filter=False, # æˆ‘ä»¬è‡ªå·±åšäº† VADï¼Œæ‰€ä»¥è¿™é‡Œå…³æ‰å†…ç½®çš„
                no_speech_threshold=0.4,
                log_prob_threshold=-0.8
            )
            
            # faster-whisper è¿”å›çš„æ˜¯ç”Ÿæˆå™¨ï¼Œéœ€è¦éå†å‡ºæ¥
            text = "".join([segment.text for segment in segments]).strip()
            
            if len(text) > 1 and text != last_text and not is_hallucination(text):
                cost_time = time.time() - start_t
                timestamp = time.strftime("%H:%M:%S")
                line = f"[{timestamp}] (ğŸš€{cost_time:.2f}s) {text}"
                print(line)
                with open(log_file, "a", encoding="utf-8") as f:
                    f.write(line + "\n")
                last_text = text
                        
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    main()